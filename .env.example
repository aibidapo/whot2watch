# Whot2Watch Environment Configuration
# Copy this file to .env.local and fill in the values

# =============================================================================
# Database
# =============================================================================
DATABASE_URL=postgresql://user:password@localhost:5432/whot2watch

# =============================================================================
# Redis
# =============================================================================
REDIS_URL=redis://localhost:6379

# =============================================================================
# OpenSearch
# =============================================================================
OPENSEARCH_URL=http://localhost:9200

# =============================================================================
# External APIs
# =============================================================================
TMDB_API_KEY=your_tmdb_api_key_here
OMDB_API_KEY=your_omdb_api_key_here
TRAKT_CLIENT_ID=your_trakt_client_id_here

# =============================================================================
# Authentication (Auth0)
# =============================================================================
AUTH0_DOMAIN=your-tenant.auth0.com
AUTH0_AUDIENCE=https://api.whot2watch.local
AUTH0_CLIENT_ID=your_client_id_here

# =============================================================================
# AI & MCP Configuration (Epic 8)
# =============================================================================

# Feature Flags
AI_CONCIERGE_ENABLED=false          # Enable/disable AI chat endpoint
NLU_ENABLED=true                    # Enable/disable NLU parsing (fallback to filters)
SOCIAL_FEED_ENABLED=false           # Include friends' activity in chat context

# LLM Provider Selection
LLM_PROVIDER=none                   # Options: anthropic | openai | none
ANTHROPIC_API_KEY=                  # Required if LLM_PROVIDER=anthropic
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Anthropic model to use
OPENAI_API_KEY=                     # Required if LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4o                 # OpenAI model to use

# LLM Settings
LLM_MAX_TOKENS=1024                 # Maximum tokens per response
LLM_TEMPERATURE=0.7                 # Response creativity (0.0 - 1.0)

# =============================================================================
# Cost Controls (Epic 8 / Epic 12)
# =============================================================================
LLM_DAILY_LIMIT_FREE=10             # Messages/day for free tier users
LLM_DAILY_LIMIT_PREMIUM=1000        # Messages/day for premium tier users
LLM_MONTHLY_BUDGET_USD=500          # Alert threshold for monthly LLM spend
LLM_PER_REQUEST_MAX_TOKENS=2048     # Maximum tokens per single request

# =============================================================================
# Safety Configuration (Epic 8)
# =============================================================================
CHAT_PROMPT_REDACTION=true          # Hash prompts in logs (no raw text)
CHAT_SAFETY_FILTER=true             # Enable content filtering on inputs/outputs

# =============================================================================
# Chat Rate Limiting (Epic 8 / Epic 9)
# =============================================================================
CHAT_RATE_LIMIT_WINDOW_MS=60000     # Rate limit window in milliseconds
CHAT_RATE_LIMIT_FREE=5              # Max requests per window for free tier
CHAT_RATE_LIMIT_PREMIUM=30          # Max requests per window for premium tier

# =============================================================================
# Session Configuration
# =============================================================================
CHAT_MAX_TURNS=20                   # Maximum conversation turns before truncation
CHAT_SESSION_TTL_SECONDS=1800       # Session expiry (30 minutes default)
CHAT_MAX_HISTORY_TOKENS=4000        # Max tokens to include from history

# =============================================================================
# MCP Configuration
# =============================================================================
MCP_ENABLED=true                    # Enable MCP server integration
MCP_TMDB_ENABLED=true               # Enable TMDB MCP server
MCP_JUSTWATCH_ENABLED=true          # Enable JustWatch MCP server
MCP_LAZY_LOAD=true                  # Lazy load MCP servers on first use
MCP_CACHE_SECONDS=300               # Cache MCP responses for 5 minutes
MCP_MAX_RETRIES=3                   # Retry failed MCP calls
MCP_BACKOFF_MS=1000                 # Initial backoff for retries

# =============================================================================
# Availability Source (Epic 1)
# =============================================================================
# Controls where streaming availability data comes from
# Options: LOCAL | TMDB | JUSTWATCH | WATCHMODE
AVAILABILITY_SOURCE=LOCAL

# =============================================================================
# Analytics (Epic 5)
# =============================================================================
ANALYTICS_WEBHOOK_URL=              # Webhook endpoint for analytics events
ANALYTICS_BUFFER_SIZE=100           # Batch size before flushing events
ANALYTICS_FLUSH_INTERVAL_MS=5000    # Flush interval in milliseconds

# =============================================================================
# Monetization & Growth (Epic 9)
# =============================================================================
PLAN_ENFORCEMENT_ENABLED=false      # Gate premium features server-side
PREMIUM_TRIAL_DAYS=14               # Trial duration in days
FREE_LIST_LIMIT=5                   # Max lists for free tier
AFFILIATES_ENABLED=false            # Enable affiliate link params
AFFILIATE_DISCLOSURE_TEXT=Some links may earn us a commission at no extra cost to you.
AFFILIATE_PROVIDER_TAGS=            # JSON map of provider-specific affiliate tags
REFERRAL_ENABLED=false              # Enable referral/invite system
PUBLIC_API_KEYS=                    # Comma-separated API keys for B2B partners

# =============================================================================
# Server Configuration
# =============================================================================
PORT=4000                           # API server port
NODE_ENV=development                # Environment: development | production | test
LOG_LEVEL=info                      # Log level: debug | info | warn | error
